{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NgxBd7p9IJw0","executionInfo":{"status":"ok","timestamp":1695823781931,"user_tz":-420,"elapsed":16365,"user":{"displayName":"duy nguyen","userId":"07830227504687194710"}},"outputId":"554c3c34-b5cc-4b04-b81c-73064d9606fd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"markdown","source":["# Mục mới"],"metadata":{"id":"QGGCcSF3oKth"}},{"cell_type":"markdown","source":["# Mục mới"],"metadata":{"id":"AEJl5BIHbhzs"}},{"cell_type":"code","source":["!pip install emoji\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YLqz1JBTM-i1","executionInfo":{"status":"ok","timestamp":1695946414539,"user_tz":-420,"elapsed":5913,"user":{"displayName":"duy nguyen","userId":"07830227504687194710"}},"outputId":"1a591da1-83d8-438d-a099-2099d55e2e1a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting emoji\n","  Downloading emoji-2.8.0-py2.py3-none-any.whl (358 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/358.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m256.0/358.9 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m358.9/358.9 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: emoji\n","Successfully installed emoji-2.8.0\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"-Bj1Y-RJkbAe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696129968921,"user_tz":-420,"elapsed":22566,"user":{"displayName":"duy nguyen","userId":"07830227504687194710"}},"outputId":"c875cac8-a36b-4f0b-8cf4-ad4e90e3f066"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!pip install vncorenlp\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LEKTImGBNIkU","executionInfo":{"status":"ok","timestamp":1695946319048,"user_tz":-420,"elapsed":7456,"user":{"displayName":"duy nguyen","userId":"07830227504687194710"}},"outputId":"891da4dc-2f4b-48b8-88f9-8421391f4cb0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting vncorenlp\n","  Downloading vncorenlp-1.0.3.tar.gz (2.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from vncorenlp) (2.31.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->vncorenlp) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->vncorenlp) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->vncorenlp) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->vncorenlp) (2023.7.22)\n","Building wheels for collected packages: vncorenlp\n","  Building wheel for vncorenlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for vncorenlp: filename=vncorenlp-1.0.3-py3-none-any.whl size=2645932 sha256=da3c81d5758a173dfd4d5e2cd2d9937380581abc3019144a6aac5ffc2f640a18\n","  Stored in directory: /root/.cache/pip/wheels/5d/d9/b3/41f6c6b1ab758561fd4aab55dc0480b9d7a131c6aaa573a3fa\n","Successfully built vncorenlp\n","Installing collected packages: vncorenlp\n","Successfully installed vncorenlp-1.0.3\n"]}]},{"cell_type":"code","source":["import regex as re\n","import string\n","import emoji\n","import pandas as pd\n","from vncorenlp import VnCoreNLP\n","from nltk import flatten\n"],"metadata":{"id":"GCEULpleM1Fk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["annotator = VnCoreNLP('https://github.com/vncorenlp/VnCoreNLP')\n"],"metadata":{"id":"Nd7_PendScNO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["n  def remove_HTML(text):\n","    return re.sub(r'<[^>]*>', '', text)\n","\n","\n","# Chuẩn hoá unicode\n","def convert_unicode(text):\n","    char1252 = 'à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ'\n","    charutf8 = 'à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ'\n","    char1252 = char1252.split('|')\n","    charutf8 = charutf8.split('|')\n","\n","    dic = {}\n","    for i in range(len(char1252)): dic[char1252[i]] = charutf8[i]\n","    return re.sub(\n","        r'à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ',\n","        lambda x: dic[x.group()], text\n","    )\n","\n","\n","# Standardize accent typing\n","# Dùng ánh xạ để xác định thuộc loại\n","vowels_to_ids = {}\n","vowels_table = [\n","    ['a', 'à', 'á', 'ả', 'ã', 'ạ', 'a' ],\n","    ['ă', 'ằ', 'ắ', 'ẳ', 'ẵ', 'ặ', 'aw'],\n","    ['â', 'ầ', 'ấ', 'ẩ', 'ẫ', 'ậ', 'aa'],\n","    ['e', 'è', 'é', 'ẻ', 'ẽ', 'ẹ', 'e' ],\n","    ['ê', 'ề', 'ế', 'ể', 'ễ', 'ệ', 'ee'],\n","    ['i', 'ì', 'í', 'ỉ', 'ĩ', 'ị', 'i' ],\n","    ['o', 'ò', 'ó', 'ỏ', 'õ', 'ọ', 'o' ],\n","    ['ô', 'ồ', 'ố', 'ổ', 'ỗ', 'ộ', 'oo'],\n","    ['ơ', 'ờ', 'ớ', 'ở', 'ỡ', 'ợ', 'ow'],\n","    ['u', 'ù', 'ú', 'ủ', 'ũ', 'ụ', 'u' ],\n","    ['ư', 'ừ', 'ứ', 'ử', 'ữ', 'ự', 'uw'],\n","    ['y', 'ỳ', 'ý', 'ỷ', 'ỹ', 'ỵ', 'y' ]\n","]\n","\n","for i in range(len(vowels_table)):\n","    for j in range(len(vowels_table[i]) - 1):\n","        vowels_to_ids[vowels_table[i][j]] = (i, j)\n","\n","\n","def is_valid_vietnamese_word(word):\n","    # Kiểm tra xem các ký tự nguyên âm có liền nhau hay không\n","    chars = list(word)\n","    vowel_indexes = -1\n","    for index, char in enumerate(chars):\n","        x, y = vowels_to_ids.get(char, (-1, -1))\n","        if x != -1:\n","            if vowel_indexes == -1: vowel_indexes = index\n","            else:\n","                if index - vowel_indexes != 1: return False\n","                vowel_indexes = index\n","    return True\n","\n","\n","def standardize_word_typing(word):\n","    '''\n","    Chuẩn hoá các nguyên âm trong tiếng việt dựa trên nguyên\n","    tắc đặt dấu thanh trong chữ quốc ngữ (kiểu cũ)\n","    ==> Việc này giúp giảm thiểu các từ trong từ điển\n","    ==> Tăng performance.\n","\n","    VD: gỉa, giả ==> Đưa về giả\n","\n","    Tham khảo: https://vi.wikipedia.org/wiki/Quy_t%E1%BA%AFc_%C4%91%E1%BA%B7t_d%E1%BA%A5u_thanh_trong_ch%E1%BB%AF_qu%E1%BB%91c_ng%E1%BB%AF\n","    '''\n","\n","    # Nếu không phải từ tiếng việt hợp lệ thì ta không cần chuẩn hoá các nguyên âm\n","    if not is_valid_vietnamese_word(word): return word\n","    chars = list(word)\n","    dau_cau = 0\n","    vowel_indexes = []\n","    qu_or_gi = False\n","\n","    # Trong tiếng việt có 2 phụ âm kép có ký tự thành phần giống nguyên âm\n","    # là qu và gi, vì vậy ta cần tránh nhầm lẫn các ký tự u, i trong\n","    # qu và gi là nguyên âm.\n","    for index, char in enumerate(chars):\n","        x, y = vowels_to_ids.get(char, (-1, -1))\n","        if x == -1: continue\n","        elif x == 9:  # check qu\n","            if index != 0 and chars[index - 1] == 'q':\n","                chars[index] = 'u'\n","                qu_or_gi = True\n","        elif x == 5:  # check gi\n","            if index != 0 and chars[index - 1] == 'g':\n","                chars[index] = 'i'\n","                qu_or_gi = True\n","\n","        # Nếu y != 0, thì từ sẽ có dấu câu (hỏi, ngã, nặng, ...)\n","        if y != 0:\n","            dau_cau = y\n","            chars[index] = vowels_table[x][0]\n","\n","        # Nếu ký tự hiện tại nằm trong bảng nguyên âm\n","        # và không phải là ký tự trong phụ âm qu, gi thì ta\n","        # sẽ chèn vào vowel_indexes\n","        if not qu_or_gi or index != 1:\n","            vowel_indexes.append(index)\n","\n","    # Trường hợp từ có 0 hoặc 1 nguyên âm\n","    if len(vowel_indexes) < 2:\n","        # Vì dấu thanh chỉ có khả năng trên nguyên âm, nên các trường hợp phụ âm\n","        # không phải qu hoặc gi ta chỉ cần trả về từ gốc.\n","        if qu_or_gi:\n","            # Ví dụ: gỉ sau đợt xử lý trên sẽ được tách thành list chas ['g', 'i']\n","            # và dau_cau = 3 (dấu hỏi) thì ta sẽ trả lại đúng thành gỉ\n","            if len(chars) == 2:\n","                x, y = vowels_to_ids.get(chars[1])\n","                chars[1] = vowels_table[x][dau_cau]\n","\n","            # Nếu có 1 nguyên âm, thì nguyên âm này sẽ được trả về đúng dấu thanh ban đầu.\n","            # VD: \"giả\" hoặc \"gỉa\" ==> ['g', 'i', 'a'] và dấu câu là hỏi ==> giả\n","            else:\n","                x, y = vowels_to_ids.get(chars[2], (-1, -1))\n","                if x != -1: chars[2] = vowels_table[x][dau_cau]\n","                else: chars[1] = vowels_table[5][dau_cau] if chars[1] == 'i' else vowels_table[9][dau_cau]\n","            return ''.join(chars)\n","        return word\n","\n","    # Ngoại lệ là chữ \"ê\" và \"ơ\" chiếm ưu tiên, bất kể vị trí.\n","    for index in vowel_indexes:\n","        x, y = vowels_to_ids[chars[index]]\n","        if x == 4 or x == 8:  # ê, ơ\n","            chars[index] = vowels_table[x][dau_cau]\n","            return ''.join(chars)\n","\n","    # Nếu là tập hợp hai (2) nguyên âm (nguyên âm đôi) thì đánh dấu ở nguyên âm đầu.\n","    # Tập hợp ba (3) nguyên âm (nguyên âm ba) hoặc hai nguyên âm + phụ âm cuối\n","    # thì vị trí dấu chuyển đến nguyên âm thứ nhì\n","    if len(vowel_indexes) == 2:\n","        if vowel_indexes[-1] == len(chars) - 1:\n","            x, y = vowels_to_ids[chars[vowel_indexes[0]]]\n","            chars[vowel_indexes[0]] = vowels_table[x][dau_cau]\n","        else:\n","            x, y = vowels_to_ids[chars[vowel_indexes[1]]]\n","            chars[vowel_indexes[1]] = vowels_table[x][dau_cau]\n","    else:\n","        x, y = vowels_to_ids[chars[vowel_indexes[1]]]\n","        chars[vowel_indexes[1]] = vowels_table[x][dau_cau]\n","    return ''.join(chars)\n","\n","\n","def standardize_sentence_typing(text):\n","    words = text.lower().split()\n","    for index, word in enumerate(words):\n","        # Dùng regex để tách thành cụm có dạng \"<dấu câu>/<word>/<dấu câu>\"\n","        cw = re.sub(r'(^\\p{P}*)([p{L}.]*\\p{L}+)(\\p{P}*$)', r'\\1/\\2/\\3', word).split('/')\n","        if len(cw) == 3: cw[1] = standardize_word_typing(cw[1])\n","        words[index] = ''.join(cw)\n","    return ' '.join(words)\n","\n","\n","# Chuẩn hoá từ viết tắt\n","# !wget https://gist.githubusercontent.com/nguyenvanhieuvn/7d9441c10b3c2739499fc5a4d9ea06fb/raw/df939245b3e841b62af115be4dcb3516dadc9fc5/teencode.txt\n","replace_list = {\n","    'ô kêi': 'ok', 'okie': 'ok', 'o kê': 'ok', 'okey': 'ok', 'ôkê': 'ok', 'oki': 'ok', 'oke': 'ok', 'okay': 'ok', 'okê': 'ok',\n","    'tks': 'cảm ơn', 'thks': 'cảm ơn', 'thanks': 'cảm ơn', 'ths': 'cảm ơn', 'thank': 'cảm ơn',\n","    'kg': 'không', 'not': 'không', 'k': 'không', 'kh': 'không', 'kô': 'không', 'hok': 'không', 'ko': 'không', 'khong': 'không', 'kp': 'không phải',\n","    'he he': 'tích cực', 'hehe': 'tích cực', 'hihi': 'tích cực', 'haha': 'tích cực', 'hjhj': 'tích cực', 'thick': 'tích cực',\n","    'lol': 'tiêu cực', 'cc': 'tiêu cực', 'huhu': 'tiêu cực', 'cute': 'dễ thương',\n","\n","    'sz': 'cỡ', 'size': 'cỡ',\n","    'wa': 'quá', 'wá': 'quá', 'qá': 'quá',\n","    'đx': 'được', 'dk': 'được', 'dc': 'được', 'đk': 'được', 'đc': 'được',\n","    'vs': 'với', 'j': 'gì', '“': ' ', 'time': 'thời gian', 'm': 'mình', 'mik': 'mình', 'r': 'rồi', 'bjo': 'bao giờ', 'very': 'rất',\n","\n","    'authentic': 'chuẩn chính hãng', 'aut': 'chuẩn chính hãng', 'auth': 'chuẩn chính hãng', 'date': 'hạn sử dụng', 'hsd': 'hạn sử dụng',\n","    'store': 'cửa hàng', 'sop': 'cửa hàng', 'shopE': 'cửa hàng', 'shop': 'cửa hàng',\n","    'sp': 'sản phẩm', 'product': 'sản phẩm', 'hàg': 'hàng',\n","    'ship': 'giao hàng', 'delivery': 'giao hàng', 'síp': 'giao hàng', 'order': 'đặt hàng',\n","\n","    'gud': 'tốt', 'wel done': 'tốt', 'good': 'tốt', 'gút': 'tốt', 'tot': 'tốt', 'nice': 'tốt', 'perfect': 'rất tốt',\n","    'quality': 'chất lượng', 'chất lg': 'chất lượng', 'chat': 'chất', 'excelent': 'hoàn hảo', 'bt': 'bình thường',\n","    'sad': 'tệ', 'por': 'tệ', 'poor': 'tệ', 'bad': 'tệ',\n","    'beautiful': 'đẹp tuyệt vời', 'dep': 'đẹp',\n","    'xau': 'xấu', 'sấu': 'xấu',\n","\n","    'thik': 'thích', 'iu': 'yêu', 'fake': 'giả mạo',\n","    'quickly': 'nhanh', 'quick': 'nhanh', 'fast': 'nhanh',\n","    'fresh': 'tươi', 'delicious': 'ngon',\n","\n","    'dt': 'điện thoại', 'fb': 'facebook', 'face': 'facebook', 'ks': 'khách sạn', 'nv': 'nhân viên',\n","    'nt': 'nhắn tin', 'ib': 'nhắn tin', 'tl': 'trả lời', 'trl': 'trả lời', 'rep': 'trả lời',\n","    'fback': 'feedback', 'fedback': 'feedback',\n","    'sd': 'sử dụng', 'sài': 'xài',\n","\n","    '😊': 'tích cực', '🙂': 'tích cực', '🙁': 'tiêu cực',\n","    '❤️': 'tích cực', '👍': 'tích cực', '🎉': 'tích cực', '😀': 'tích cực', '😍': 'tích cực', '😂': 'tích cực', '🤗': 'tích cực', '😙': 'tích cực', '🙂': 'tích cực',\n","    '😔': 'tiêu cực', '😓': 'tiêu cực',\n","    '⭐': 'star', '*': 'star', '🌟': 'star'\n","}\n","\n","with open('/content/drive/MyDrive/Colab Notebooks/teencode.txt', encoding='utf-8') as f:\n","    for pair in f.readlines():\n","        key, value = pair.split('\\t')\n","        replace_list[key] = value.strip()\n","\n","\n","def normalize_acronyms(text):\n","    words = []\n","    for word in text.strip().split():\n","        # word = word.strip(string.punctuation)\n","        if word.lower() not in replace_list.keys(): words.append(word)\n","        else: words.append(replace_list[word.lower()])\n","    return emoji.demojize(' '.join(words)) # Remove Emojis\n"],"metadata":{"id":"K8JzuYrTNHvQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["annotator = VnCoreNLP('/content/drive/MyDrive/Colab Notebooks/VnCoreNLP/VnCoreNLP-1.1.1.jar')\n","def word_segmentation(text):\n","    words = annotator.tokenize(text)\n","    return ' '.join(word for word in flatten(words))"],"metadata":{"id":"ysae510c606o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def remove_unnecessary_characters(text):\n","    text = re.sub(r'[^\\s\\wáàảãạăắằẳẵặâấầẩẫậéèẻẽẹêếềểễệóòỏõọôốồổỗộơớờởỡợíìỉĩịúùủũụưứừửữựýỳỷỹỵđÁÀẢÃẠĂẮẰẲẴẶÂẤẦẨẪẬÉÈẺẼẸÊẾỀỂỄỆÓÒỎÕỌÔỐỒỔỖỘƠỚỜỞỠỢÍÌỈĨỊÚÙỦŨỤƯỨỪỬỮỰÝỲỶỸỴĐ_]', ' ', text)\n","    text = re.sub(r'\\s+', ' ', text).strip() # Remove extra whitespace\n","    return text\n"],"metadata":{"id":"zqFT7WT57WHC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def text_preprocess(text):\n","    text = remove_HTML(text)\n","    text = convert_unicode(text)\n","    text = standardize_sentence_typing(text)\n","    text = normalize_acronyms(text)\n","    text = word_segmentation(text) # When use PhoBERT\n","    text = remove_unnecessary_characters(text)\n","    return text.lower()\n"],"metadata":{"id":"zcslakcb7LL9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import py_vncorenlp\n","\n","# Automatically download VnCoreNLP components from the original repository\n","# and save them in some local machine folder\n","\n","# Load the word and sentence segmentation component\n","rdrsegmenter = py_vncorenlp.VnCoreNLP(annotators=[\"wseg\"], save_dir='/absolute/path/to/vncorenlp')\n","\n","text = \"Ông Nguyễn Khắc Chúc  đang làm việc tại Đại học Quốc gia Hà Nội. Bà Lan, vợ ông Chúc, cũng làm việc tại đây.\"\n","\n","output = rdrsegmenter.word_segment(text)\n","\n","print(output)\n","# ['Ông Nguyễn_Khắc_Chúc đang làm_việc tại Đại_học Quốc_gia Hà_Nội .', 'Bà Lan , vợ ông Chúc , cũng làm_việc tại đây .']"],"metadata":{"id":"I40Jf3BJAmu5","colab":{"base_uri":"https://localhost:8080/","height":383},"executionInfo":{"status":"error","timestamp":1696032589531,"user_tz":-420,"elapsed":10,"user":{"displayName":"Thanh Hoài Từ","userId":"11788687463552434154"}},"outputId":"e0dc40f4-440a-4527-ecfc-bc228101fda1"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-9bcc9dc92d13>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpy_vncorenlp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Automatically download VnCoreNLP components from the original repository\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# and save them in some local machine folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'py_vncorenlp'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":["annotator = VnCoreNLP('/content/drive/MyDrive/Colab Notebooks/VnCoreNLP')\n"],"metadata":{"id":"4sRxQtBjB8F9","colab":{"base_uri":"https://localhost:8080/","height":325},"executionInfo":{"status":"error","timestamp":1695946440584,"user_tz":-420,"elapsed":11,"user":{"displayName":"duy nguyen","userId":"07830227504687194710"}},"outputId":"f5264d57-668d-49c5-8b5c-5d165bf479fc"},"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-0007ea70ccd2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mannotator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVnCoreNLP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Colab Notebooks/VnCoreNLP'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vncorenlp/vncorenlp.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, address, port, timeout, annotators, max_heap_size, quiet)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;31m# Check if VnCoreNLP file exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'File \"%s\" was not found, please check again.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0maddress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;31m# Check if VnCoreNLPServer file exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: File \"/content/drive/MyDrive/Colab Notebooks/VnCoreNLP\" was not found, please check again."]}]}]}