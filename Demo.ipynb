{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NgxBd7p9IJw0","executionInfo":{"status":"ok","timestamp":1695823781931,"user_tz":-420,"elapsed":16365,"user":{"displayName":"duy nguyen","userId":"07830227504687194710"}},"outputId":"554c3c34-b5cc-4b04-b81c-73064d9606fd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"markdown","source":["# Má»¥c má»›i"],"metadata":{"id":"QGGCcSF3oKth"}},{"cell_type":"markdown","source":["# Má»¥c má»›i"],"metadata":{"id":"AEJl5BIHbhzs"}},{"cell_type":"code","source":["!pip install emoji\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YLqz1JBTM-i1","executionInfo":{"status":"ok","timestamp":1695946414539,"user_tz":-420,"elapsed":5913,"user":{"displayName":"duy nguyen","userId":"07830227504687194710"}},"outputId":"1a591da1-83d8-438d-a099-2099d55e2e1a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting emoji\n","  Downloading emoji-2.8.0-py2.py3-none-any.whl (358 kB)\n","\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/358.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m256.0/358.9 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m358.9/358.9 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: emoji\n","Successfully installed emoji-2.8.0\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"-Bj1Y-RJkbAe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696129968921,"user_tz":-420,"elapsed":22566,"user":{"displayName":"duy nguyen","userId":"07830227504687194710"}},"outputId":"c875cac8-a36b-4f0b-8cf4-ad4e90e3f066"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!pip install vncorenlp\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LEKTImGBNIkU","executionInfo":{"status":"ok","timestamp":1695946319048,"user_tz":-420,"elapsed":7456,"user":{"displayName":"duy nguyen","userId":"07830227504687194710"}},"outputId":"891da4dc-2f4b-48b8-88f9-8421391f4cb0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting vncorenlp\n","  Downloading vncorenlp-1.0.3.tar.gz (2.6 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from vncorenlp) (2.31.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->vncorenlp) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->vncorenlp) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->vncorenlp) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->vncorenlp) (2023.7.22)\n","Building wheels for collected packages: vncorenlp\n","  Building wheel for vncorenlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for vncorenlp: filename=vncorenlp-1.0.3-py3-none-any.whl size=2645932 sha256=da3c81d5758a173dfd4d5e2cd2d9937380581abc3019144a6aac5ffc2f640a18\n","  Stored in directory: /root/.cache/pip/wheels/5d/d9/b3/41f6c6b1ab758561fd4aab55dc0480b9d7a131c6aaa573a3fa\n","Successfully built vncorenlp\n","Installing collected packages: vncorenlp\n","Successfully installed vncorenlp-1.0.3\n"]}]},{"cell_type":"code","source":["import regex as re\n","import string\n","import emoji\n","import pandas as pd\n","from vncorenlp import VnCoreNLP\n","from nltk import flatten\n"],"metadata":{"id":"GCEULpleM1Fk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["annotator = VnCoreNLP('https://github.com/vncorenlp/VnCoreNLP')\n"],"metadata":{"id":"Nd7_PendScNO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["n  def remove_HTML(text):\n","    return re.sub(r'<[^>]*>', '', text)\n","\n","\n","# Chuáº©n hoÃ¡ unicode\n","def convert_unicode(text):\n","    char1252 = 'aÌ€|aÌ|aÌ‰|aÌƒ|aÌ£|Ã¢Ì€|Ã¢Ì|Ã¢Ì‰|Ã¢Ìƒ|Ã¢Ì£|ÄƒÌ€|ÄƒÌ|ÄƒÌ‰|ÄƒÌƒ|ÄƒÌ£|eÌ€|eÌ|eÌ‰|eÌƒ|eÌ£|ÃªÌ€|ÃªÌ|ÃªÌ‰|ÃªÌƒ|ÃªÌ£|iÌ€|iÌ|iÌ‰|iÌƒ|iÌ£|oÌ€|oÌ|oÌ‰|oÌƒ|oÌ£|Ã´Ì€|Ã´Ì|Ã´Ì‰|Ã´Ìƒ|Ã´Ì£|Æ¡Ì€|Æ¡Ì|Æ¡Ì‰|Æ¡Ìƒ|Æ¡Ì£|uÌ€|uÌ|uÌ‰|uÌƒ|uÌ£|Æ°Ì€|Æ°Ì|Æ°Ì‰|Æ°Ìƒ|Æ°Ì£|yÌ€|yÌ|yÌ‰|yÌƒ|yÌ£|AÌ€|AÌ|AÌ‰|AÌƒ|AÌ£|Ã‚Ì€|Ã‚Ì|Ã‚Ì‰|Ã‚Ìƒ|Ã‚Ì£|Ä‚Ì€|Ä‚Ì|Ä‚Ì‰|Ä‚Ìƒ|Ä‚Ì£|EÌ€|EÌ|EÌ‰|EÌƒ|EÌ£|ÃŠÌ€|ÃŠÌ|ÃŠÌ‰|ÃŠÌƒ|ÃŠÌ£|IÌ€|IÌ|IÌ‰|IÌƒ|IÌ£|OÌ€|OÌ|OÌ‰|OÌƒ|OÌ£|Ã”Ì€|Ã”Ì|Ã”Ì‰|Ã”Ìƒ|Ã”Ì£|Æ Ì€|Æ Ì|Æ Ì‰|Æ Ìƒ|Æ Ì£|UÌ€|UÌ|UÌ‰|UÌƒ|UÌ£|Æ¯Ì€|Æ¯Ì|Æ¯Ì‰|Æ¯Ìƒ|Æ¯Ì£|YÌ€|YÌ|YÌ‰|YÌƒ|YÌ£'\n","    charutf8 = 'Ã |Ã¡|áº£|Ã£|áº¡|áº§|áº¥|áº©|áº«|áº­|áº±|áº¯|áº³|áºµ|áº·|Ã¨|Ã©|áº»|áº½|áº¹|á»|áº¿|á»ƒ|á»…|á»‡|Ã¬|Ã­|á»‰|Ä©|á»‹|Ã²|Ã³|á»|Ãµ|á»|á»“|á»‘|á»•|á»—|á»™|á»|á»›|á»Ÿ|á»¡|á»£|Ã¹|Ãº|á»§|Å©|á»¥|á»«|á»©|á»­|á»¯|á»±|á»³|Ã½|á»·|á»¹|á»µ|Ã€|Ã|áº¢|Ãƒ|áº |áº¦|áº¤|áº¨|áºª|áº¬|áº°|áº®|áº²|áº´|áº¶|Ãˆ|Ã‰|áºº|áº¼|áº¸|á»€|áº¾|á»‚|á»„|á»†|ÃŒ|Ã|á»ˆ|Ä¨|á»Š|Ã’|Ã“|á»|Ã•|á»Œ|á»’|á»|á»”|á»–|á»˜|á»œ|á»š|á»|á» |á»¢|Ã™|Ãš|á»¦|Å¨|á»¤|á»ª|á»¨|á»¬|á»®|á»°|á»²|Ã|á»¶|á»¸|á»´'\n","    char1252 = char1252.split('|')\n","    charutf8 = charutf8.split('|')\n","\n","    dic = {}\n","    for i in range(len(char1252)): dic[char1252[i]] = charutf8[i]\n","    return re.sub(\n","        r'aÌ€|aÌ|aÌ‰|aÌƒ|aÌ£|Ã¢Ì€|Ã¢Ì|Ã¢Ì‰|Ã¢Ìƒ|Ã¢Ì£|ÄƒÌ€|ÄƒÌ|ÄƒÌ‰|ÄƒÌƒ|ÄƒÌ£|eÌ€|eÌ|eÌ‰|eÌƒ|eÌ£|ÃªÌ€|ÃªÌ|ÃªÌ‰|ÃªÌƒ|ÃªÌ£|iÌ€|iÌ|iÌ‰|iÌƒ|iÌ£|oÌ€|oÌ|oÌ‰|oÌƒ|oÌ£|Ã´Ì€|Ã´Ì|Ã´Ì‰|Ã´Ìƒ|Ã´Ì£|Æ¡Ì€|Æ¡Ì|Æ¡Ì‰|Æ¡Ìƒ|Æ¡Ì£|uÌ€|uÌ|uÌ‰|uÌƒ|uÌ£|Æ°Ì€|Æ°Ì|Æ°Ì‰|Æ°Ìƒ|Æ°Ì£|yÌ€|yÌ|yÌ‰|yÌƒ|yÌ£|AÌ€|AÌ|AÌ‰|AÌƒ|AÌ£|Ã‚Ì€|Ã‚Ì|Ã‚Ì‰|Ã‚Ìƒ|Ã‚Ì£|Ä‚Ì€|Ä‚Ì|Ä‚Ì‰|Ä‚Ìƒ|Ä‚Ì£|EÌ€|EÌ|EÌ‰|EÌƒ|EÌ£|ÃŠÌ€|ÃŠÌ|ÃŠÌ‰|ÃŠÌƒ|ÃŠÌ£|IÌ€|IÌ|IÌ‰|IÌƒ|IÌ£|OÌ€|OÌ|OÌ‰|OÌƒ|OÌ£|Ã”Ì€|Ã”Ì|Ã”Ì‰|Ã”Ìƒ|Ã”Ì£|Æ Ì€|Æ Ì|Æ Ì‰|Æ Ìƒ|Æ Ì£|UÌ€|UÌ|UÌ‰|UÌƒ|UÌ£|Æ¯Ì€|Æ¯Ì|Æ¯Ì‰|Æ¯Ìƒ|Æ¯Ì£|YÌ€|YÌ|YÌ‰|YÌƒ|YÌ£',\n","        lambda x: dic[x.group()], text\n","    )\n","\n","\n","# Standardize accent typing\n","# DÃ¹ng Ã¡nh xáº¡ Ä‘á»ƒ xÃ¡c Ä‘á»‹nh thuá»™c loáº¡i\n","vowels_to_ids = {}\n","vowels_table = [\n","    ['a', 'Ã ', 'Ã¡', 'áº£', 'Ã£', 'áº¡', 'a' ],\n","    ['Äƒ', 'áº±', 'áº¯', 'áº³', 'áºµ', 'áº·', 'aw'],\n","    ['Ã¢', 'áº§', 'áº¥', 'áº©', 'áº«', 'áº­', 'aa'],\n","    ['e', 'Ã¨', 'Ã©', 'áº»', 'áº½', 'áº¹', 'e' ],\n","    ['Ãª', 'á»', 'áº¿', 'á»ƒ', 'á»…', 'á»‡', 'ee'],\n","    ['i', 'Ã¬', 'Ã­', 'á»‰', 'Ä©', 'á»‹', 'i' ],\n","    ['o', 'Ã²', 'Ã³', 'á»', 'Ãµ', 'á»', 'o' ],\n","    ['Ã´', 'á»“', 'á»‘', 'á»•', 'á»—', 'á»™', 'oo'],\n","    ['Æ¡', 'á»', 'á»›', 'á»Ÿ', 'á»¡', 'á»£', 'ow'],\n","    ['u', 'Ã¹', 'Ãº', 'á»§', 'Å©', 'á»¥', 'u' ],\n","    ['Æ°', 'á»«', 'á»©', 'á»­', 'á»¯', 'á»±', 'uw'],\n","    ['y', 'á»³', 'Ã½', 'á»·', 'á»¹', 'á»µ', 'y' ]\n","]\n","\n","for i in range(len(vowels_table)):\n","    for j in range(len(vowels_table[i]) - 1):\n","        vowels_to_ids[vowels_table[i][j]] = (i, j)\n","\n","\n","def is_valid_vietnamese_word(word):\n","    # Kiá»ƒm tra xem cÃ¡c kÃ½ tá»± nguyÃªn Ã¢m cÃ³ liá»n nhau hay khÃ´ng\n","    chars = list(word)\n","    vowel_indexes = -1\n","    for index, char in enumerate(chars):\n","        x, y = vowels_to_ids.get(char, (-1, -1))\n","        if x != -1:\n","            if vowel_indexes == -1: vowel_indexes = index\n","            else:\n","                if index - vowel_indexes != 1: return False\n","                vowel_indexes = index\n","    return True\n","\n","\n","def standardize_word_typing(word):\n","    '''\n","    Chuáº©n hoÃ¡ cÃ¡c nguyÃªn Ã¢m trong tiáº¿ng viá»‡t dá»±a trÃªn nguyÃªn\n","    táº¯c Ä‘áº·t dáº¥u thanh trong chá»¯ quá»‘c ngá»¯ (kiá»ƒu cÅ©)\n","    ==> Viá»‡c nÃ y giÃºp giáº£m thiá»ƒu cÃ¡c tá»« trong tá»« Ä‘iá»ƒn\n","    ==> TÄƒng performance.\n","\n","    VD: gá»‰a, giáº£ ==> ÄÆ°a vá» giáº£\n","\n","    Tham kháº£o: https://vi.wikipedia.org/wiki/Quy_t%E1%BA%AFc_%C4%91%E1%BA%B7t_d%E1%BA%A5u_thanh_trong_ch%E1%BB%AF_qu%E1%BB%91c_ng%E1%BB%AF\n","    '''\n","\n","    # Náº¿u khÃ´ng pháº£i tá»« tiáº¿ng viá»‡t há»£p lá»‡ thÃ¬ ta khÃ´ng cáº§n chuáº©n hoÃ¡ cÃ¡c nguyÃªn Ã¢m\n","    if not is_valid_vietnamese_word(word): return word\n","    chars = list(word)\n","    dau_cau = 0\n","    vowel_indexes = []\n","    qu_or_gi = False\n","\n","    # Trong tiáº¿ng viá»‡t cÃ³ 2 phá»¥ Ã¢m kÃ©p cÃ³ kÃ½ tá»± thÃ nh pháº§n giá»‘ng nguyÃªn Ã¢m\n","    # lÃ  qu vÃ  gi, vÃ¬ váº­y ta cáº§n trÃ¡nh nháº§m láº«n cÃ¡c kÃ½ tá»± u, i trong\n","    # qu vÃ  gi lÃ  nguyÃªn Ã¢m.\n","    for index, char in enumerate(chars):\n","        x, y = vowels_to_ids.get(char, (-1, -1))\n","        if x == -1: continue\n","        elif x == 9:  # check qu\n","            if index != 0 and chars[index - 1] == 'q':\n","                chars[index] = 'u'\n","                qu_or_gi = True\n","        elif x == 5:  # check gi\n","            if index != 0 and chars[index - 1] == 'g':\n","                chars[index] = 'i'\n","                qu_or_gi = True\n","\n","        # Náº¿u y != 0, thÃ¬ tá»« sáº½ cÃ³ dáº¥u cÃ¢u (há»i, ngÃ£, náº·ng, ...)\n","        if y != 0:\n","            dau_cau = y\n","            chars[index] = vowels_table[x][0]\n","\n","        # Náº¿u kÃ½ tá»± hiá»‡n táº¡i náº±m trong báº£ng nguyÃªn Ã¢m\n","        # vÃ  khÃ´ng pháº£i lÃ  kÃ½ tá»± trong phá»¥ Ã¢m qu, gi thÃ¬ ta\n","        # sáº½ chÃ¨n vÃ o vowel_indexes\n","        if not qu_or_gi or index != 1:\n","            vowel_indexes.append(index)\n","\n","    # TrÆ°á»ng há»£p tá»« cÃ³ 0 hoáº·c 1 nguyÃªn Ã¢m\n","    if len(vowel_indexes) < 2:\n","        # VÃ¬ dáº¥u thanh chá»‰ cÃ³ kháº£ nÄƒng trÃªn nguyÃªn Ã¢m, nÃªn cÃ¡c trÆ°á»ng há»£p phá»¥ Ã¢m\n","        # khÃ´ng pháº£i qu hoáº·c gi ta chá»‰ cáº§n tráº£ vá» tá»« gá»‘c.\n","        if qu_or_gi:\n","            # VÃ­ dá»¥: gá»‰ sau Ä‘á»£t xá»­ lÃ½ trÃªn sáº½ Ä‘Æ°á»£c tÃ¡ch thÃ nh list chas ['g', 'i']\n","            # vÃ  dau_cau = 3 (dáº¥u há»i) thÃ¬ ta sáº½ tráº£ láº¡i Ä‘Ãºng thÃ nh gá»‰\n","            if len(chars) == 2:\n","                x, y = vowels_to_ids.get(chars[1])\n","                chars[1] = vowels_table[x][dau_cau]\n","\n","            # Náº¿u cÃ³ 1 nguyÃªn Ã¢m, thÃ¬ nguyÃªn Ã¢m nÃ y sáº½ Ä‘Æ°á»£c tráº£ vá» Ä‘Ãºng dáº¥u thanh ban Ä‘áº§u.\n","            # VD: \"giáº£\" hoáº·c \"gá»‰a\" ==> ['g', 'i', 'a'] vÃ  dáº¥u cÃ¢u lÃ  há»i ==> giáº£\n","            else:\n","                x, y = vowels_to_ids.get(chars[2], (-1, -1))\n","                if x != -1: chars[2] = vowels_table[x][dau_cau]\n","                else: chars[1] = vowels_table[5][dau_cau] if chars[1] == 'i' else vowels_table[9][dau_cau]\n","            return ''.join(chars)\n","        return word\n","\n","    # Ngoáº¡i lá»‡ lÃ  chá»¯ \"Ãª\" vÃ  \"Æ¡\" chiáº¿m Æ°u tiÃªn, báº¥t ká»ƒ vá»‹ trÃ­.\n","    for index in vowel_indexes:\n","        x, y = vowels_to_ids[chars[index]]\n","        if x == 4 or x == 8:  # Ãª, Æ¡\n","            chars[index] = vowels_table[x][dau_cau]\n","            return ''.join(chars)\n","\n","    # Náº¿u lÃ  táº­p há»£p hai (2) nguyÃªn Ã¢m (nguyÃªn Ã¢m Ä‘Ã´i) thÃ¬ Ä‘Ã¡nh dáº¥u á»Ÿ nguyÃªn Ã¢m Ä‘áº§u.\n","    # Táº­p há»£p ba (3) nguyÃªn Ã¢m (nguyÃªn Ã¢m ba) hoáº·c hai nguyÃªn Ã¢m + phá»¥ Ã¢m cuá»‘i\n","    # thÃ¬ vá»‹ trÃ­ dáº¥u chuyá»ƒn Ä‘áº¿n nguyÃªn Ã¢m thá»© nhÃ¬\n","    if len(vowel_indexes) == 2:\n","        if vowel_indexes[-1] == len(chars) - 1:\n","            x, y = vowels_to_ids[chars[vowel_indexes[0]]]\n","            chars[vowel_indexes[0]] = vowels_table[x][dau_cau]\n","        else:\n","            x, y = vowels_to_ids[chars[vowel_indexes[1]]]\n","            chars[vowel_indexes[1]] = vowels_table[x][dau_cau]\n","    else:\n","        x, y = vowels_to_ids[chars[vowel_indexes[1]]]\n","        chars[vowel_indexes[1]] = vowels_table[x][dau_cau]\n","    return ''.join(chars)\n","\n","\n","def standardize_sentence_typing(text):\n","    words = text.lower().split()\n","    for index, word in enumerate(words):\n","        # DÃ¹ng regex Ä‘á»ƒ tÃ¡ch thÃ nh cá»¥m cÃ³ dáº¡ng \"<dáº¥u cÃ¢u>/<word>/<dáº¥u cÃ¢u>\"\n","        cw = re.sub(r'(^\\p{P}*)([p{L}.]*\\p{L}+)(\\p{P}*$)', r'\\1/\\2/\\3', word).split('/')\n","        if len(cw) == 3: cw[1] = standardize_word_typing(cw[1])\n","        words[index] = ''.join(cw)\n","    return ' '.join(words)\n","\n","\n","# Chuáº©n hoÃ¡ tá»« viáº¿t táº¯t\n","# !wget https://gist.githubusercontent.com/nguyenvanhieuvn/7d9441c10b3c2739499fc5a4d9ea06fb/raw/df939245b3e841b62af115be4dcb3516dadc9fc5/teencode.txt\n","replace_list = {\n","    'Ã´ kÃªi': 'ok', 'okie': 'ok', 'o kÃª': 'ok', 'okey': 'ok', 'Ã´kÃª': 'ok', 'oki': 'ok', 'oke': 'ok', 'okay': 'ok', 'okÃª': 'ok',\n","    'tks': 'cáº£m Æ¡n', 'thks': 'cáº£m Æ¡n', 'thanks': 'cáº£m Æ¡n', 'ths': 'cáº£m Æ¡n', 'thank': 'cáº£m Æ¡n',\n","    'kg': 'khÃ´ng', 'not': 'khÃ´ng', 'k': 'khÃ´ng', 'kh': 'khÃ´ng', 'kÃ´': 'khÃ´ng', 'hok': 'khÃ´ng', 'ko': 'khÃ´ng', 'khong': 'khÃ´ng', 'kp': 'khÃ´ng pháº£i',\n","    'he he': 'tÃ­ch cá»±c', 'hehe': 'tÃ­ch cá»±c', 'hihi': 'tÃ­ch cá»±c', 'haha': 'tÃ­ch cá»±c', 'hjhj': 'tÃ­ch cá»±c', 'thick': 'tÃ­ch cá»±c',\n","    'lol': 'tiÃªu cá»±c', 'cc': 'tiÃªu cá»±c', 'huhu': 'tiÃªu cá»±c', 'cute': 'dá»… thÆ°Æ¡ng',\n","\n","    'sz': 'cá»¡', 'size': 'cá»¡',\n","    'wa': 'quÃ¡', 'wÃ¡': 'quÃ¡', 'qÃ¡': 'quÃ¡',\n","    'Ä‘x': 'Ä‘Æ°á»£c', 'dk': 'Ä‘Æ°á»£c', 'dc': 'Ä‘Æ°á»£c', 'Ä‘k': 'Ä‘Æ°á»£c', 'Ä‘c': 'Ä‘Æ°á»£c',\n","    'vs': 'vá»›i', 'j': 'gÃ¬', 'â€œ': ' ', 'time': 'thá»i gian', 'm': 'mÃ¬nh', 'mik': 'mÃ¬nh', 'r': 'rá»“i', 'bjo': 'bao giá»', 'very': 'ráº¥t',\n","\n","    'authentic': 'chuáº©n chÃ­nh hÃ£ng', 'aut': 'chuáº©n chÃ­nh hÃ£ng', 'auth': 'chuáº©n chÃ­nh hÃ£ng', 'date': 'háº¡n sá»­ dá»¥ng', 'hsd': 'háº¡n sá»­ dá»¥ng',\n","    'store': 'cá»­a hÃ ng', 'sop': 'cá»­a hÃ ng', 'shopE': 'cá»­a hÃ ng', 'shop': 'cá»­a hÃ ng',\n","    'sp': 'sáº£n pháº©m', 'product': 'sáº£n pháº©m', 'hÃ g': 'hÃ ng',\n","    'ship': 'giao hÃ ng', 'delivery': 'giao hÃ ng', 'sÃ­p': 'giao hÃ ng', 'order': 'Ä‘áº·t hÃ ng',\n","\n","    'gud': 'tá»‘t', 'wel done': 'tá»‘t', 'good': 'tá»‘t', 'gÃºt': 'tá»‘t', 'tot': 'tá»‘t', 'nice': 'tá»‘t', 'perfect': 'ráº¥t tá»‘t',\n","    'quality': 'cháº¥t lÆ°á»£ng', 'cháº¥t lg': 'cháº¥t lÆ°á»£ng', 'chat': 'cháº¥t', 'excelent': 'hoÃ n háº£o', 'bt': 'bÃ¬nh thÆ°á»ng',\n","    'sad': 'tá»‡', 'por': 'tá»‡', 'poor': 'tá»‡', 'bad': 'tá»‡',\n","    'beautiful': 'Ä‘áº¹p tuyá»‡t vá»i', 'dep': 'Ä‘áº¹p',\n","    'xau': 'xáº¥u', 'sáº¥u': 'xáº¥u',\n","\n","    'thik': 'thÃ­ch', 'iu': 'yÃªu', 'fake': 'giáº£ máº¡o',\n","    'quickly': 'nhanh', 'quick': 'nhanh', 'fast': 'nhanh',\n","    'fresh': 'tÆ°Æ¡i', 'delicious': 'ngon',\n","\n","    'dt': 'Ä‘iá»‡n thoáº¡i', 'fb': 'facebook', 'face': 'facebook', 'ks': 'khÃ¡ch sáº¡n', 'nv': 'nhÃ¢n viÃªn',\n","    'nt': 'nháº¯n tin', 'ib': 'nháº¯n tin', 'tl': 'tráº£ lá»i', 'trl': 'tráº£ lá»i', 'rep': 'tráº£ lá»i',\n","    'fback': 'feedback', 'fedback': 'feedback',\n","    'sd': 'sá»­ dá»¥ng', 'sÃ i': 'xÃ i',\n","\n","    'ğŸ˜Š': 'tÃ­ch cá»±c', 'ğŸ™‚': 'tÃ­ch cá»±c', 'ğŸ™': 'tiÃªu cá»±c',\n","    'â¤ï¸': 'tÃ­ch cá»±c', 'ğŸ‘': 'tÃ­ch cá»±c', 'ğŸ‰': 'tÃ­ch cá»±c', 'ğŸ˜€': 'tÃ­ch cá»±c', 'ğŸ˜': 'tÃ­ch cá»±c', 'ğŸ˜‚': 'tÃ­ch cá»±c', 'ğŸ¤—': 'tÃ­ch cá»±c', 'ğŸ˜™': 'tÃ­ch cá»±c', 'ğŸ™‚': 'tÃ­ch cá»±c',\n","    'ğŸ˜”': 'tiÃªu cá»±c', 'ğŸ˜“': 'tiÃªu cá»±c',\n","    'â­': 'star', '*': 'star', 'ğŸŒŸ': 'star'\n","}\n","\n","with open('/content/drive/MyDrive/Colab Notebooks/teencode.txt', encoding='utf-8') as f:\n","    for pair in f.readlines():\n","        key, value = pair.split('\\t')\n","        replace_list[key] = value.strip()\n","\n","\n","def normalize_acronyms(text):\n","    words = []\n","    for word in text.strip().split():\n","        # word = word.strip(string.punctuation)\n","        if word.lower() not in replace_list.keys(): words.append(word)\n","        else: words.append(replace_list[word.lower()])\n","    return emoji.demojize(' '.join(words)) # Remove Emojis\n"],"metadata":{"id":"K8JzuYrTNHvQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["annotator = VnCoreNLP('/content/drive/MyDrive/Colab Notebooks/VnCoreNLP/VnCoreNLP-1.1.1.jar')\n","def word_segmentation(text):\n","    words = annotator.tokenize(text)\n","    return ' '.join(word for word in flatten(words))"],"metadata":{"id":"ysae510c606o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def remove_unnecessary_characters(text):\n","    text = re.sub(r'[^\\s\\wÃ¡Ã áº£Ã£áº¡Äƒáº¯áº±áº³áºµáº·Ã¢áº¥áº§áº©áº«áº­Ã©Ã¨áº»áº½áº¹Ãªáº¿á»á»ƒá»…á»‡Ã³Ã²á»Ãµá»Ã´á»‘á»“á»•á»—á»™Æ¡á»›á»á»Ÿá»¡á»£Ã­Ã¬á»‰Ä©á»‹ÃºÃ¹á»§Å©á»¥Æ°á»©á»«á»­á»¯á»±Ã½á»³á»·á»¹á»µÄ‘ÃÃ€áº¢Ãƒáº Ä‚áº®áº°áº²áº´áº¶Ã‚áº¤áº¦áº¨áºªáº¬Ã‰Ãˆáººáº¼áº¸ÃŠáº¾á»€á»‚á»„á»†Ã“Ã’á»Ã•á»ŒÃ”á»á»’á»”á»–á»˜Æ á»šá»œá»á» á»¢ÃÃŒá»ˆÄ¨á»ŠÃšÃ™á»¦Å¨á»¤Æ¯á»¨á»ªá»¬á»®á»°Ãá»²á»¶á»¸á»´Ä_]', ' ', text)\n","    text = re.sub(r'\\s+', ' ', text).strip() # Remove extra whitespace\n","    return text\n"],"metadata":{"id":"zqFT7WT57WHC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def text_preprocess(text):\n","    text = remove_HTML(text)\n","    text = convert_unicode(text)\n","    text = standardize_sentence_typing(text)\n","    text = normalize_acronyms(text)\n","    text = word_segmentation(text) # When use PhoBERT\n","    text = remove_unnecessary_characters(text)\n","    return text.lower()\n"],"metadata":{"id":"zcslakcb7LL9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import py_vncorenlp\n","\n","# Automatically download VnCoreNLP components from the original repository\n","# and save them in some local machine folder\n","\n","# Load the word and sentence segmentation component\n","rdrsegmenter = py_vncorenlp.VnCoreNLP(annotators=[\"wseg\"], save_dir='/absolute/path/to/vncorenlp')\n","\n","text = \"Ã”ng Nguyá»…n Kháº¯c ChÃºc  Ä‘ang lÃ m viá»‡c táº¡i Äáº¡i há»c Quá»‘c gia HÃ  Ná»™i. BÃ  Lan, vá»£ Ã´ng ChÃºc, cÅ©ng lÃ m viá»‡c táº¡i Ä‘Ã¢y.\"\n","\n","output = rdrsegmenter.word_segment(text)\n","\n","print(output)\n","# ['Ã”ng Nguyá»…n_Kháº¯c_ChÃºc Ä‘ang lÃ m_viá»‡c táº¡i Äáº¡i_há»c Quá»‘c_gia HÃ _Ná»™i .', 'BÃ  Lan , vá»£ Ã´ng ChÃºc , cÅ©ng lÃ m_viá»‡c táº¡i Ä‘Ã¢y .']"],"metadata":{"id":"I40Jf3BJAmu5","colab":{"base_uri":"https://localhost:8080/","height":383},"executionInfo":{"status":"error","timestamp":1696032589531,"user_tz":-420,"elapsed":10,"user":{"displayName":"Thanh HoÃ i Tá»«","userId":"11788687463552434154"}},"outputId":"e0dc40f4-440a-4527-ecfc-bc228101fda1"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-9bcc9dc92d13>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpy_vncorenlp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Automatically download VnCoreNLP components from the original repository\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# and save them in some local machine folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'py_vncorenlp'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":["annotator = VnCoreNLP('/content/drive/MyDrive/Colab Notebooks/VnCoreNLP')\n"],"metadata":{"id":"4sRxQtBjB8F9","colab":{"base_uri":"https://localhost:8080/","height":325},"executionInfo":{"status":"error","timestamp":1695946440584,"user_tz":-420,"elapsed":11,"user":{"displayName":"duy nguyen","userId":"07830227504687194710"}},"outputId":"f5264d57-668d-49c5-8b5c-5d165bf479fc"},"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-0007ea70ccd2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mannotator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVnCoreNLP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Colab Notebooks/VnCoreNLP'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vncorenlp/vncorenlp.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, address, port, timeout, annotators, max_heap_size, quiet)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;31m# Check if VnCoreNLP file exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'File \"%s\" was not found, please check again.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0maddress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;31m# Check if VnCoreNLPServer file exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: File \"/content/drive/MyDrive/Colab Notebooks/VnCoreNLP\" was not found, please check again."]}]}]}