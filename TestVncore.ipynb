{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"14cqYfifWFeQWQmIgC07lHOB_8dnU5HCb","authorship_tag":"ABX9TyPSVePTotxShRzDMus0UB0Y"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qcCl4EGYjSVp","executionInfo":{"status":"ok","timestamp":1695951104207,"user_tz":-420,"elapsed":21168,"user":{"displayName":"duy nguyen","userId":"07830227504687194710"}},"outputId":"7d1c7f14-09ee-4252-cef4-750fd0c25c61"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'transformers'...\n","remote: Enumerating objects: 143694, done.\u001b[K\n","remote: Total 143694 (delta 0), reused 0 (delta 0), pack-reused 143694\u001b[K\n","Receiving objects: 100% (143694/143694), 148.09 MiB | 23.09 MiB/s, done.\n","Resolving deltas: 100% (107443/107443), done.\n"]}],"source":["!git clone  https://github.com/datquocnguyen/transformers.git"]},{"cell_type":"code","source":["!pip3 install tokenizers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MO4KiBk2jYtY","executionInfo":{"status":"ok","timestamp":1695951116480,"user_tz":-420,"elapsed":8956,"user":{"displayName":"duy nguyen","userId":"07830227504687194710"}},"outputId":"8e3888e7-0c64-4d3e-efb6-488d32ec1bea"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tokenizers\n","  Downloading tokenizers-0.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting huggingface_hub<0.17,>=0.16.4 (from tokenizers)\n","  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<0.17,>=0.16.4->tokenizers) (3.12.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<0.17,>=0.16.4->tokenizers) (2023.6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<0.17,>=0.16.4->tokenizers) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<0.17,>=0.16.4->tokenizers) (4.66.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<0.17,>=0.16.4->tokenizers) (6.0.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<0.17,>=0.16.4->tokenizers) (4.5.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<0.17,>=0.16.4->tokenizers) (23.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<0.17,>=0.16.4->tokenizers) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<0.17,>=0.16.4->tokenizers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<0.17,>=0.16.4->tokenizers) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<0.17,>=0.16.4->tokenizers) (2023.7.22)\n","Installing collected packages: huggingface_hub, tokenizers\n","Successfully installed huggingface_hub-0.16.4 tokenizers-0.14.0\n"]}]},{"cell_type":"code","source":["!pip install py_vncorenlp"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2RshQMCUkht3","executionInfo":{"status":"ok","timestamp":1695951363997,"user_tz":-420,"elapsed":3344,"user":{"displayName":"duy nguyen","userId":"07830227504687194710"}},"outputId":"0cf41b8d-871a-4733-f91d-b4337cc645f0"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: py_vncorenlp in /usr/local/lib/python3.10/dist-packages (0.1.4)\n","Requirement already satisfied: pyjnius in /usr/local/lib/python3.10/dist-packages (from py_vncorenlp) (1.5.0)\n"]}]},{"cell_type":"code","source":["import py_vncorenlp\n","\n","# Automatically download VnCoreNLP components from the original repository\n","# and save them in some local machine folder\n","py_vncorenlp.download_model(save_dir='https://github.com/vncorenlp/VnCoreNLP/tree/master/models')\n","\n","# Load the word and sentence segmentation component\n","rdrsegmenter = py_vncorenlp.VnCoreNLP(annotators=[\"wseg\"], save_dir='https://github.com/vncorenlp/VnCoreNLP')\n","\n","text = \"Ông Nguyễn Khắc Chúc  đang làm việc tại Đại học Quốc gia Hà Nội. Bà Lan, vợ ông Chúc, cũng làm việc tại đây.\"\n","\n","output = rdrsegmenter.word_segment(text)\n","\n","print(output)\n","# ['Ông Nguyễn_Khắc_Chúc đang làm_việc tại Đại_học Quốc_gia Hà_Nội .', 'Bà Lan , vợ ông Chúc , cũng làm_việc tại đây .']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":379},"id":"HRjL2DCNkR3j","executionInfo":{"status":"error","timestamp":1695951459302,"user_tz":-420,"elapsed":663,"user":{"displayName":"duy nguyen","userId":"07830227504687194710"}},"outputId":"cd005ea5-335c-481f-b47f-c2c4cb3bbadc"},"execution_count":5,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-fe2c94bd3ce7>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Automatically download VnCoreNLP components from the original repository\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# and save them in some local machine folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpy_vncorenlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'https://github.com/vncorenlp/VnCoreNLP'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Load the word and sentence segmentation component\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py_vncorenlp/vncorenlp.py\u001b[0m in \u001b[0;36mdownload_model\u001b[0;34m(save_dir)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"VnCoreNLP model folder \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msave_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" already exists! Please load VnCoreNLP from this folder!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/models\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/models/dep\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/models/ner\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'https://github.com/vncorenlp/VnCoreNLP/models'"]}]}]}